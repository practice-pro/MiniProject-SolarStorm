{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G1z8M7L8eHDA",
        "outputId": "aef4daa0-d2f8-4e50-ec3f-5d166f519064"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting utils\n",
            "  Downloading utils-1.0.1-py2.py3-none-any.whl (21 kB)\n",
            "Installing collected packages: utils\n",
            "Successfully installed utils-1.0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GUBa6XE5bVhh"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import random_split\n",
        "import os\n",
        "import torch.nn as nn\n",
        "from argparse import ArgumentParser, Namespace\n",
        "import enum\n",
        "from pathlib import Path\n",
        "from typing import Dict\n",
        "from datetime import datetime\n",
        "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n",
        "import numpy as np\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from utils import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LuouGCB6bii1"
      },
      "outputs": [],
      "source": [
        "class DSCOVRMagneticFieldToWindProtonDataset(Dataset):\n",
        "    def __init__(self, data_path, start_year, end_year):\n",
        "        self.x = torch.tensor([]).float()\n",
        "        self.y = torch.tensor([]).float()\n",
        "        self.load_in(data_path, start_year, end_year)\n",
        "\n",
        "    def load_in(self, data_path, start_year, end_year):\n",
        "        for year in range(start_year, end_year+1):\n",
        "            year_data = torch.load(os.path.join(data_path, f\"data_{year}.pt\"))\n",
        "            self.x = torch.cat([self.x, year_data[\"X\"].float()], dim=0)\n",
        "            self.y = torch.cat([self.y, year_data[\"Y\"].float()], dim=0)\n",
        "        print(\"total x shape:\", self.x.shape)\n",
        "        print(\"total y shape:\", self.y.shape)\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return self.x.shape[0]\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.x[index, :, :], self.y[index, :, :]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_FoVbWwmbndv"
      },
      "outputs": [],
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        input_dim: int,\n",
        "        hidden_dim: int,\n",
        "        output_dim: int,\n",
        "        num_layers: int) -> None:\n",
        "        super(Seq2Seq, self).__init__()\n",
        "\n",
        "        self.rnn = nn.GRU(input_dim, hidden_dim, num_layers, batch_first=True)\n",
        "        self.dnn = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, output_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, seq: torch.Tensor) -> torch.Tensor:\n",
        "        output, hn = self.rnn(seq)\n",
        "        output = self.dnn(output)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9jAIMKQebrhG"
      },
      "outputs": [],
      "source": [
        "from torchmetrics.wrappers import multioutput"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "  dataset=torch.load(\"/content/drive/MyDrive/data_2021.pt\")\n",
        "  d=DSCOVRMagneticFieldToWindMagneticField('/content/drive/MyDrive',2021,2021)\n",
        "  data_len= len(d)\n",
        "  train_ratio,test_ratio = 0.7,0.3\n",
        "  train_len= int(data_len*train_ratio)\n",
        "  test_len= data_len - train_len\n",
        "  train_dataset,test_dataset = random_split(d, [train_len,test_len])\n",
        "  print(f\"train,test dataset len: {len(train_dataset)}, {len(test_dataset)}\")\n",
        "  train_loader = DataLoader(train_dataset,10000, shuffle=True)\n",
        "  test_loader = DataLoader(test_dataset, 10000, shuffle=False)\n",
        "  model = Seq2Seq(3,3,3,3)\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=0.8)\n",
        "  scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.5, patience=2, min_lr=5e-5)\n",
        "  criterion = torch.nn.MSELoss()\n",
        "  loss_train=0\n",
        "  prev_train=100\n",
        "  while abs(loss_train-prev_train)>0.001:\n",
        "    model.train()\n",
        "    prev_train=loss_train\n",
        "    loss_train, acc_train, iterations= 0, 0, 0\n",
        "    for x_prime, y in train_loader:\n",
        "      outputs = model(x_prime)\n",
        "      loss = criterion(outputs, y)\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      iterations += 1\n",
        "      loss_train += loss.item()\n",
        "    loss_train /= iterations\n",
        "    print(f\"train_loss: {loss_train:.4f}\")\n",
        "    torch.save(model.state_dict(), os.path.join(\"/content/drive/MyDrive\", \"dscovr_proton3.pt\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AzUdKi3iEW_J",
        "outputId": "a42c3570-0f78-462d-c61d-49006731b7fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total x_prime shape: torch.Size([8, 10000, 3])\n",
            "total x shape: torch.Size([8, 10000, 3])\n",
            "train,test dataset len: 5, 3\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7fceb388e650>\n",
            "train_loss: 2.2955\n",
            "train_loss: 2.7485\n",
            "train_loss: 2.4303\n",
            "train_loss: 3.8339\n",
            "train_loss: 1.7122\n",
            "train_loss: 1.2457\n",
            "train_loss: 1.6948\n",
            "train_loss: 1.4540\n",
            "train_loss: 1.1415\n",
            "train_loss: 1.2264\n",
            "train_loss: 1.4117\n",
            "train_loss: 1.3211\n",
            "train_loss: 1.1573\n",
            "train_loss: 1.1737\n",
            "train_loss: 1.2818\n",
            "train_loss: 1.2750\n",
            "train_loss: 1.1680\n",
            "train_loss: 1.1396\n",
            "train_loss: 1.2125\n",
            "train_loss: 1.2285\n",
            "train_loss: 1.1635\n",
            "train_loss: 1.1389\n",
            "train_loss: 1.1708\n",
            "train_loss: 1.1845\n",
            "train_loss: 1.1622\n",
            "train_loss: 1.1396\n",
            "train_loss: 1.1445\n",
            "train_loss: 1.1611\n",
            "train_loss: 1.1541\n",
            "train_loss: 1.1358\n",
            "train_loss: 1.1356\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Seq2Seq(3,3,3,3)\n",
        "model.load_state_dict(torch.load(os.path.join('/content/drive/MyDrive', \"dscovr_proton3.pt\")))\n",
        "model.eval()\n",
        "acc_test=0\n",
        "with torch.no_grad():\n",
        "  loss_test, acc_test, iter_test = 0, 0, 0\n",
        "  for x_prime, y in test_loader:\n",
        "    outputs = model(x_prime)\n",
        "    loss = criterion(outputs, y)\n",
        "    print(loss.item())\n",
        "    iter_test += 1\n",
        "    loss_test += loss.item()\n",
        "    for i in range(outputs.shape[0]):\n",
        "      for j in range(outputs.shape[1]):\n",
        "        for k in range(outputs.shape[2]):\n",
        "          if loss_test<1.1 and abs(outputs[i][j][k]-y[i][j][k])<=loss_test:\n",
        "            acc_test+=1\n",
        "          elif abs(outputs[i][j][k]-y[i][j][k])<1.4:\n",
        "            acc_test+=1\n",
        "  loss_test /= iter_test\n",
        "  acc_test/=(outputs.shape[0])*(outputs.shape[1])*(outputs.shape[2])\n",
        "  no=outputs.numpy()\n",
        "  ny=y.numpy()\n",
        "  nof=np.ndarray.flatten(no)\n",
        "  nyf=np.ndarray.flatten(ny)\n",
        "  correlation=np.correlate(nof,nyf)\n",
        "  print(nyf)\n",
        "  print(nof)\n",
        "  print(f\"accuracy:{acc_test*100:.2f},test_loss: {loss_test:.4f}\")\n",
        "  visualize_path = os.path.join('/content/drive/MyDrive', \"visualize\")\n",
        "  if not os.path.exists(visualize_path):\n",
        "    os.mkdir(visualize_path)\n",
        "  with torch.no_grad():\n",
        "    predictions = torch.tensor([]).to('cpu')\n",
        "    truthy = torch.tensor([]).to('cpu')\t"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RHPcTAiqFhna",
        "outputId": "b392e430-0021-495f-ab73-460735f00a46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0436975955963135\n",
            "[-1.2606956  -1.2207489   1.9505613  ... -0.46414185 -2.2159753\n",
            "  1.2354926 ]\n",
            "[ 2.3952012  -3.9514227   1.6521806  ...  0.40122044 -1.6959336\n",
            "  1.1675054 ]\n",
            "accuracy:89.03,test_loss: 1.0437\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}